---
output: 
  github_document: 
    df_print: kable
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(magrittr)
```
# resist_oped

Identifying the author behind New York Time's op-ed from [*inside the Trump White House*](https://www.nytimes.com/2018/09/05/opinion/trump-white-house-anonymous-resistance.html).

```{r}
## corr matrix
mat <- readRDS("data/mat.rds")

## print matrix
cor(t(mat))[, "op-ed"] %>% sort()

## corrplot
cormat <- cor(t(mat))
cormat <- cormat[order(cormat[, "op-ed"]), ]
colnames(cormat) <- NULL
cormat <- cormat[23:43, 23:43]
row.names(cormat) <- paste0(
	seq_len(nrow(cormat)), ". ", row.names(cormat))
cols <- c("#cc4444", "#ffeeff", "#0033ee")
cols <- colorRampPalette(cols)(200)
par(mar = c(0, 0, 0, 0))
corrplot::corrplot(cormat, type = "lower", col = cols,
	tl.pos = "ld", tl.col = "#000000", srt = 0)
```


## Data

I compared the paragraphs of the op-ed to tweets posted to timelines by members of the Cabinet.

## Code

Here's the code:

```{r, eval = FALSE}
## load tidyverse
library(tidyverse)
library(rtweet)
library(rvest)

## download Twitter profiles via CSPAN's cabinet list
cab_twits <- lists_members(
	owner_user = "CSPAN", slug = "the-cabinet")

## get up to 3200 of most recent tweets for each
cab_tweets <- cab_twits %>%
	filter(screen_name != "realDonaldTrump") %>%
	pull(user_id) %>%
	map(get_timeline, n = 3200) %>%
	bind_rows()

## scrape source code for op-ed
nyt <- read_html(
	"https://www.nytimes.com/2018/09/05/opinion/trump-white-house-anonymous-resistance.html")

## return just the paragraph text
nyt_text <- nyt %>%
	html_nodes("p") %>%
	html_text() %>%
	.[3:31]

## create data set with just author (id) and text
data <- data_frame(
	id = c(cab_tweets$screen_name, rep("op-ed", length(nyt_text))),
	text = c(cab_tweets$text, nyt_text)
)

## feature extraction
tf <- textfeatures::textfeatures(data, word_dims = 80, threads = 20)

## summarise by id
tfsum <- tf %>%
	group_by(id) %>%
	summarise_all(mean, na.rm = TRUE) %>%
	ungroup()

## vector of unique authors
authors <- unique(tfsum$id)

## create numeric vectors of equal length for each author
cols <- map(authors,
	~ filter(tfsum, id == .x) %>% select(-id) %>% as.list() %>% unlist())

## create matrix
mat <- cols %>%
	unlist() %>%
	as.numeric() %>%
	matrix(nrow = length(authors), byrow = TRUE)

## set row and column names
row.names(mat) <- authors

## dipslay matrix
cor(t(mat))[, "op-ed"] %>% sort()
```
